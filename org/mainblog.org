#+title: Main Blog
#+author: Rylan Lens Kellogg
#+description: A blog for all things Lens_r.
#+created: <2023-05-29 Mon>

* HOW TO WRITE POSTS

First of all, a kind of overview of how this works. Each top-level heading (one star) with the "blogpost" tag will be exported by the publishing system to its own file, and have its own webpage on the website that will be linked to from the main blog page. Everything else /does/ get exported to HTML, but only within the (not linked) =mainblog.html=. Which means readers of the blog won't see it :^).

Here's an example blog post. It's quite simple. It has a title (the headline of the top-level org heading). It has a =blogpost= tag. It has a unique =CUSTOM_ID= property and the date published (inserted with =M-x org-time-stamp-inactive=, or at least in the format of it).

Anything within this subtree will then be a part of the blog post. For now, there aren't any fancy CSS things going on, except for code being syntax highlighted. In the future I may add more properties so that certain pieces of text may be marked up in unique ways, but for now, we're going bare org-mode.

#+begin_src org
  \* Ooops, out of order! :blogpost:
    :PROPERTIES:
    :CUSTOM_ID: outofordertest
    :PUBLISHED: [2023-05-29 Mon 12:40]
    :MODIFIED: [2023-05-29 Mon 12:40]
    :OG_IMAGE: images/myimage.png
    :END:

    Hmm, will this be in order?
#+end_src

NOTE: The OG_IMAGE property is optional, but, if provided, sets the open graph/twitter card image (og:image) that will be displayed when the page is linked to from social media sites. OG_DESCRIPTION may also be set in order to explicitly set og:description.


* Fun Titles / Idea Dump

** How I Built Rome in a Day
[2023-06-01 Thu 16:14]


* Assembly Is *Not* What It Seems :blogpost:
:PROPERTIES:
:CUSTOM_ID: assemblynotwhatseems
:PUBLISHED: [2023-06-03 Sat 12:39]
:MODIFIED: [2023-06-04 Sun 09:17]
:OG_DESCRIPTION: Exploring Assembly from a CPU's Point of View
:END:

Assembly is as close as you can get to the hardware, right? It basically tells you the exact instructions the CPU will run ... /right/?. Well, that may be what it seems like (and what people say), but not necessarily! Modern CPUs do so much more than just read an instruction and execute it, and that is what we will be exploring in this post.

** Why Is This the Prevailing Assumption?

Well, the reason assembly is thought of as "telling the hardware exactly what to do" is because ... well, it does, strictly from a programmer's point of view. But there's a distinction here that's important. It does not tell the CPU /how/ to do it. So while, yes, you may feed it an assembly instruction to add two numbers, any one CPU may choose to do an OR operation instead, if one of the numbers is known to be zero. This sort of behaviour, where the CPU can technically do whatever it wants as long as the expected result is acquired, allows for **lots** of optimisations that would not otherwise be possible. For related reading, see /sequential consistency/ and /unspecified behaviour/.

# While I would like to say the laborious work of the hardware designers to develop such complex optimisations and efficient systems is the /sole/ reason you can sit here with a browser open to multiple tabs, background services running, multiprocessing, etc, that's just not the case. Modern computers have sped up significantly, just at a base level. The clock speed of Intel's first CPU in 1971 was 740kHz, while the max clock speed of Intel's i7-13700k is 5.4GHz; that's a 7297x increase in the 52 years from 1971 to 2023. That's not to say the optimisations don't contribute to the amazing things computers are used for nowadays, just that humans have improved in a multitude of fields of study over this time, and all of these improvements have contributed to making computers that much faster, power-efficient, and more.

** How Can a CPU Do More Than One Thing at Once?

Imagining a naive CPU pipeline that does one thing at a time, we may arrive at something like this:

#+begin_example
.->  Decoder -> Processor  -.
`---------------------------+
#+end_example

The "decoder" step would decode the next instruction from memory, located by the instruction pointer, and the processor would get a decoded instruction with which to execute. While this /does/ work, it's also incredibly slower than it needs to be; for example, the decoder would decode an instruction /and then sit around doing nothing/ while the processor step computes the proper value. While the decoder is decoding the next instruction, the processor would sit around and do nothing.

NOTE: This is a whole topic in-and-of-itself. See [[https://en.wikipedia.org/wiki/Instruction_pipelining][Instruction Pipelining @wikipedia.org]]

*** Eliminating Dependencies

Sitting around doing nothing is *never* good. Luckily, we can attempt to make the situation better due to one simple fact: computations within the processor can't use or modify the instruction pointer directly (most of the time). This means the decoder /could/ start decoding the next instruction *before* the processor finishes processing the last instruction decoded. By the time the processor finishes processing, the decoder may already be ready with another instruction to execute. This increases the amount of time the processor spends doing valuable computations, making the CPU faster and computers go brrr.

#+begin_example
Decoder -> Decoded Instruction Queue
Pop(Decoded Instruction Queue) -> Processor
#+end_example

As you can see, this /eliminates a dependency/: the processor no longer relies on the decoder directly, and instead relies on the decoded instruction queue being populated. This idea, this /concept/, of eliminating a dependency reaches so far down into the roots of modern CPUs that I could not explain it in one article, or even five. Modern CPUs eliminate dependencies on a register's value by renaming registers temporarily (yes, even the "hardware registers" don't actually exist in hardware ... there is something called a register file and it contains /actual/ hardware registers and the "name" of the register it's currently bound to; this technique is called /register banking/). This register renaming fixes our little caveat above with the instruction pointer being used in a computation. Just copy the value of the instruction pointer into a new register and rename that register to the instruction pointer for that instruction. Poof! No need to operate directly on the instruction pointer. In fact, this works for all registers.

Now, you might be wondering, what is the advantage of eliminating a dependency on a register's value? This is where the next big step in computational speed comes from.

*** Out-Of-Order Execution

That's right; by eliminating an instruction's dependency on a register, we can actually *execute* that instruction at the same time as another instruction, given they don't have dependencies on one another. Let's take a look at this in actual x86\under{}64 assembly (in Intel syntax today, for funsies).

#+begin_src asm
0      mov rax, [my_ptr]           ;;#; rax := memory[my_ptr]
1      add rax, 2                  ;;#; rax := rax + 2
2      mov [my_ptr + 8], rax       ;;#; memory[my_ptr + 8] := rax
3      mov rax, [my_other_ptr]     ;;#; rax := memory[my_other_ptr]
4      add rax, 4                  ;;#; rax := rax + 4
5      mov [my_other_ptr + 8], rax ;;#; memory[my_other_ptr] := rax
#+end_src

Attempting to eliminate dependencies in the above code without renaming registers doesn't gain us much; ~rax~ is used in *every* instruction, and therefore each instruction is dependant on the value of ~rax~ in the last instruction. Some instructions don't alter the register operand (like storing to memory), but they still require the value of ~rax~ to be what it was at the last assignment; because ~rax~ can't be reassigned, this store would still not able to be done in parallel with an instruction that sets the value of ~rax~.

/This/ is where register renaming takes the spotlight. Because the x86\under{}64 CPU is smart enough to know which instructions set a register and which ones just use them, it can analyse the code it's about to execute and determine register dependencies. For example, instruction 0 sets the value of ~rax~ and has no dependencies. Instruction 1 sets the value of ~rax~ as well, but this time has a register dependency on the value of ~rax~ set by instruction 0. So instruction 1 /depends/ on instruction 0 already having been executed, and they cannot be executed out-of-order (or in parallel). It's a similar situation for instruction 2, as it depends on the value of ~rax~ set in instruction 1. However, instruction 3 is where it gets *interesting*. With the value of ~rax~ being set again, but this time from another place in memory, this means that any dependency on the old ~rax~ is broken. So instruction 3 has no dependencies, just like instruction 0. Instruction 4 is nearly identical to instruction 1, except this time it's dependent on the value of ~rax~ set in instruction 3. Same story for instruction 5, except dependent on instruction 4. Okay, so we can determine the register dependencies of an instruction ... but what has all this analysis got us? To showcase the value gained from doing this analysis, let's go through and give a unique name to each /value/ of ~rax~ that was depended upon.

#+begin_src asm
0      mov r1, [my_ptr]            ;;#; r1 := memory[my_ptr]
1      add r1, 2                   ;;#; r1 := r1 + 2
2      mov [my_ptr + 8], r1        ;;#; memory[my_ptr + 8] := r1
3      mov r2, [my_other_ptr]      ;;#; r2 := memory[my_other_ptr]
4      add r2, 4                   ;;#; r2 := r2 + 4
5      mov [my_other_ptr + 8], r2  ;;#; memory[my_other_ptr] := r2
#+end_src

Now, with this done, the CPU is smart enough to notice something: instructions 0 through 2 and 3 through 5 are two blocks of instructions that start with /no/ register dependencies.

#+begin_example
0 sets r1
1 uses r1 and sets r1
2 uses r1

3 sets r2
4 uses r2 and sets r2
5 uses r2
#+end_example

As neither of these blocks of instructions depend on each other for any values of any register (CPU state), this means they *can* be executed out-of-order. So, if the L1 cache has the memory at ~my_other_ptr~ already loaded, for example, the CPU could choose to execute the block of instructions that uses that memory more first, taking advantage of the already-populated cache. And that's just for a single CPU with a single logical/arithmetic unit.

At some point, humans were smart enough to realise that a CPU already has a clock, registers, instructions, etc, but, /for some reason/, only ever computes one instruction which operates on one or two registers per clock cycle. By inserting more actual logical and arithmetic units within a single CPU, it's possible for a single computational unit to compute /more than one/ calculation at a time, operating on more than just one or two of its registers. That is, for two sequential ~add~ instructions that have no dependencies on each other, it's *vastly* more efficient to send each to its own ALU and have a single clock cycle cause both of them to do their respective computations, getting both results at the same time. This idea even extends past ~add~ instructions. For example, the instruction decoder could be duplicated, allowing for multiple instructions to be decoded at once.

With modern processors, this is taken even one step further: the "CPU" has /multiple/ CPUs inside of it, each with their own set of ALUs, register files, and more. Generally, the OS chooses the CPU it starts on as the "main" CPU, and that CPU is used to dispatch heavy computations between the rest. It is up to the OS kernel how this is actually accomplished, and what the other CPUs are used for: this is the job of the /scheduler/ (another topic that I could write a million articles on and barely scratch the surface).

Modern CPUs are to assembly what C is to Python. You can use C to implement Python, but it will be a lot more verbose, detailed, and complicated than any equivalent you could come up with in Python. Modern CPUs look at assembly and /wish/ they could operate at such an abstract level, while assembly sees the CPU simply as a means to an end. So, the next time you write (or read) some assembly, remember that the CPU has other things in mind than just src_asm[:exports code]{ add rax, rax}.

Anyway, thank you for reading this post on assembly. If you enjoyed it, I make Twitch and YouTube content that you might also enjoy. To stay tuned when more posts come out, there is an RSS feed you can subscribe to.


* What /Is/ a Program? :blogpost:
:PROPERTIES:
:CUSTOM_ID: whatsaprogram
:PUBLISHED: [2023-05-29 Mon 08:41]
:MODIFIED: [2023-06-04 Sun 09:17]
:END:

This may seem obvious, but it turns out to be quite ... complex.

#+begin_src c
  int main() {
    return 69;
  }
#+end_src

Is the above code a "program"? Most will say yes, in my experience. This immediately throws a wrench into most /obvious/ definitions of program.

The code above is not executable; it's simply plain-text within a file. Well, then maybe a program /isn't/ necessarily executable, but /some/ programs /may/ be executed. So "something executable on a computer" isn't really a valid definition of "program".

Some, from here, may expand the definition to "something that may be eventually executable on a computer (after some set of transformations)". Another issue arises, however, if we look at the following example.

#+begin_src c
  int main() {
    return 69
  }
#+end_src

Is the above code a "program"? If we follow the "eventually executable" definition, it /isn't/. There is a syntax error, as the ~return~ statement is not terminated with a semi-colon. This code, therefore, isn't compileable; it's an "ill-formed program" according to the C standard. So, as we can see, some programs (without changing the source) are not *ever* executable.

So, a program isn't necessarily well-formed, a la compileable, and a program isn't necessarily executable. We're right back to the start: what /is/ a program? To me, someone who "writes programs", it would seem that the things I write would be programs. So let's take this top-down approach, and find out what we already call programs, and /only then/ begin to tighten the definition without excluding anything. What things might be a program?

- An executable file (in any format) is definitely a program.
- An object file may contain portions of or all of a program or programs.
- Source code is thought of as a program ("programmers write programs").


From there, then, let's try to fit a definition to this set of things. There's one thing you may notice: they /all/ have code in them ... just in *very* different forms. An executable file has machine code in it (among other things that tell the computer /how/ to execute the file). The object file has machine code in it (or intermediate representation if using link-time optimisation). And finally, for the source code, it's even in the name. So, as /vague/ as it is, I think that we can begin to narrow our idea of "program".

A "program" is /some form/ of instructions meant for a computer to do computations.

So that C code up above? Well, it's only written with the intent that that sequence of tokens in that language will produce a given computation. "Code" is just instructions meant for a computer, no matter if that is machine code, C code, or LISP.

However, this definition /does/ come with its own host of caveats. For example, the source code of a program fits the definition of "instructions meant for a computer", but so does the executable file generated after compiling that code. In that case, are there /two/ programs? Or just one program in two different formats? I think this is a question of philosophy, truthfully. To me, it makes the most sense that there /are/ two programs, they just have a set of instructions in different formats that /happen/ to tell the computer to do the same thing (unless your compiler is borked/I wrote it).

** Etymology of "program"

The word "program" is derived from Greek /programma/, meaning "a public written notice". (See? Even the Ancient Greeks knew that software should be open to the public :Ãž.) In the 1600s, it was used in concert and theatre, referring to an outline of what was going to happen that day (i.e. features presented, persons participating, etc). We can see from its early use that a program defines what is going to happen during a performance.

In the mid-1900s, when computers came about (thanks Alan), it stood to reason that something that tells you what the computer is going to do while it is running (during its /performance/) would be a /computer program/. And this is when it kind of got out of hand. Computers back then used punch cards as input; those punch cards, naturally, became known as programs. And at this point, everything still makes relative sense. It's not confusing what a computer program is.

*And that's exactly when it got confusing.*

Computers seriously blossomed in the years following its discovery/invention. New hardware, new software, good times. Computers upgraded from full-room behemoths that munch on punch-cards to somewhat-reasonable (although still large) machines programmed in assembly. And with this shift came an important distinction: programmers now write assembly code, but the computer no longer executes that directly. The assembly is first /assembled/ into machine code, and only then is that executed by the computer. The people who used to punch cards to tell the computer what to do? Well now they wrote source code. But to them, they were still doing the same thing: telling computers to do some computations. "Something a programmer writes" /must/ be a "program", so therefore the source code a programmer writes /must/ be a "program". On the other end, a computer would read a punch card and do execution/computation based on it. That means that the compiler's output, the actual thing fed to the computer to make it do computation, /also/ ended up being called a "program", even though these two things have been separated in reality.

Because there was no longer a physical punch card tied to a "program", the original meaning of "program" (a printed list of features, persons participating, etc. at a concert/theatre) no longer applies /at all/. The /concept/ stayed (a list of things that tells humans what's going to happen), but the actual meaning was transformed greatly. At this point, arbitrary bits on some magnetic tape were now a program. The baby was, in fact, thrown out with the bath-water.

** A Definition of "program" that I Am Comfortable With

To me, there /isn't/ a clear-cut definition of program. No matter which one you choose, there are unintuitive corner-cases. However! That does not stop me from /choosing/ a definition that I am comfortable with.

What if "program" actually equates to "instructions that tell a computer to do computations". While this /is/ incredibly vague, it is also just specific enough. For example, when you write C code, you are attempting to instruct the computer on how to do execution/computation in order to give you the result you want. And when you compile that C code into an executable, the executable also contains instructions that tells a computer how to do computations, just in a different format.

As with every definition of program, there are imperfect corner cases, but this is one I'm okay with: the /source code/ and the /executable produced from that source code/ are entirely separate programs that happen to have instructions within them that produce the same result (assuming a well-written compiler).

